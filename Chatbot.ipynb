{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seconlon99/EUProjGeo/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installations"
      ],
      "metadata": {
        "id": "sZYd2Xm9Xn7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai\n",
        "!pip install chromadb\n",
        "!pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw_b2HuZavsl",
        "outputId": "826eebc3-4a94-4654-9ea2-0ef42dc0bcc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.33.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.31.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "jYIO9NQeWTkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gFQEUuH1PYrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10994ecb-3787-4c4e-f482-b607c4edb0ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import json # For handling function call arguments and results\n",
        "\n",
        "import google.generativeai as genai\n",
        "# IMPORTANT: We only need to import FunctionDeclaration\n",
        "from google.generativeai.types import FunctionDeclaration\n",
        "from google.generativeai.types import Tool # Available in types\n",
        "from google.generativeai import protos # FunctionDeclaration and Schema are in protos\n",
        "\n",
        "# NEW: Import the generative_models module for lower-level content construction\n",
        "import google.generativeai.generative_models as glm # <<<--- ADD THIS IMPORT\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "#connecting to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key setup\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Make sure you have set GOOGLE_API_KEY in colab userdata\n",
        "\n",
        "# Configure the Gemini API\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "CSV_FILE_PATH = \"/content/drive/My Drive/MDA/merged_organization_project_data.csv\" # <--- IMPORTANT: Change this to your actual CSV file path\n",
        "CHROMA_DB_PATH = \"/content/drive/My Drive/MDA/chroma_db\"\n",
        "COLLECTION_NAME = \"project_data\"\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-004\"\n",
        "GENERATION_MODEL_NAME = 'gemini-1.5-pro' # Use gemini-1.5-pro or gemini-1.5-flash\n",
        "TOP_K_RESULTS = 5 # Number of relevant chunks to retrieve from the vector DB\n",
        "MAX_HISTORY_TURNS = 5 # Keep only the last N user-assistant turns"
      ],
      "metadata": {
        "id": "0seLIdc6EyyX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the columns need to be adjusted based on what we want to include, also their names could be adjusted based on what they mean to improve performance of the vector based storage"
      ],
      "metadata": {
        "id": "NhOfCX5ieZs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Helper Functions ---\n",
        "\n",
        "def create_text_from_row(row: pd.Series) -> str:\n",
        "    \"\"\"\n",
        "    Creates a descriptive text string from a DataFrame row for embedding.\n",
        "    You can customize this to include the most relevant columns from your CSV.\n",
        "    \"\"\"\n",
        "    # Example: Concatenate key information\n",
        "    # Adjust column names based on your actual CSV\n",
        "    city = row.get('city', 'N/A')\n",
        "    contact_form = row.get('contactForm', 'N/A')\n",
        "    content_update_date_x = row.get('contentUpdateDate_x', 'N/A')\n",
        "    country = row.get('country', 'N/A')\n",
        "    ec_contribution = row.get('ecContribution', 'N/A')\n",
        "    geolocation = row.get('geolocation', 'N/A')\n",
        "    name = row.get('name', 'N/A')\n",
        "    net_ec_contribution = row.get('netEcContribution', 'N/A')\n",
        "    organization_url = row.get('organizationURL', 'N/A')\n",
        "    post_code = row.get('postCode', 'N/A')\n",
        "    project_id = row.get('projectID', 'N/A')\n",
        "    role = row.get('role', 'N/A')\n",
        "    street = row.get('street', 'N/A')\n",
        "    total_cost_x = row.get('totalCost_x', 'N/A')\n",
        "    cultdist = row.get('cultdist', 'N/A')\n",
        "    cultdist_std = row.get('cultdist_std', 'N/A')\n",
        "    countryname = row.get('Countryname', 'N/A')\n",
        "    ec_max_contribution = row.get('ecMaxContribution', 'N/A')\n",
        "    ec_signature_date = row.get('ecSignatureDate', 'N/A')\n",
        "    end_date = row.get('endDate', 'N/A')\n",
        "    start_date = row.get('startDate', 'N/A')\n",
        "    status = row.get('status', 'N/A')\n",
        "    title = row.get('title', 'N/A')\n",
        "    goal = row.get('goal', 'N/A')\n",
        "    method = row.get('method', 'N/A')\n",
        "    generalized_goal = row.get('generalized_goal', 'N/A')\n",
        "    generalized_method = row.get('generalized method', 'N/A')\n",
        "    tech_domain = row.get('tech_domain', 'N/A')\n",
        "    strategic_method = row.get('strategic_method', 'N/A')\n",
        "    standardized_domain_area = row.get('standardized_domain_area', 'N/A')\n",
        "    standardized_method_area = row.get('standardized_method_area', 'N/A')\n",
        "    final_domain = row.get('final_domain', 'N/A')\n",
        "    final_method = row.get('final_method', 'N/A')\n",
        "    broad_domain = row.get('broad_domain', 'N/A')\n",
        "    broad_method = row.get('broad_method', 'N/A')\n",
        "\n",
        "        # Safely convert numeric fields\n",
        "    try:\n",
        "        ec_contribution_val = float(ec_contribution)\n",
        "    except (ValueError, TypeError):\n",
        "        ec_contribution_val = 'N/A'\n",
        "\n",
        "    try:\n",
        "        net_ec_contribution_val = float(net_ec_contribution)\n",
        "    except (ValueError, TypeError):\n",
        "        net_ec_contribution_val = 'N/A'\n",
        "\n",
        "    try:\n",
        "        total_cost_x_val = float(total_cost_x)\n",
        "    except (ValueError, TypeError):\n",
        "        total_cost_x_val = 'N/A'\n",
        "\n",
        "    try:\n",
        "        ec_max_contribution_val = float(ec_max_contribution)\n",
        "    except (ValueError, TypeError):\n",
        "        ec_max_contribution_val = 'N/A'\n",
        "\n",
        "    return (\n",
        "        f\"City: {city}, Contact Form: {contact_form}, \"\n",
        "        f\"Content Update Date: {content_update_date_x}, Country: {country}, EC Contribution: {ec_contribution_val}, \"\n",
        "        f\"Geolocation: {geolocation}, Name: {name}, Net EC Contribution: {net_ec_contribution}, \"\n",
        "        f\"Organization URL: {organization_url}, \"\n",
        "        f\"Post Code: {post_code}, Project ID: {project_id}, \"\n",
        "        f\"Role: {role}, Street: {street}, Total Cost of the project: {total_cost_x}, \"\n",
        "        f\"Cultural Distance: {cultdist}, Cultural Distance Std: {cultdist_std}, \"\n",
        "        f\"Country Name: {countryname},\"\n",
        "        f\"EC Max Contribution: {ec_max_contribution}, EC Signature Date: {ec_signature_date}, \"\n",
        "        f\"End Date: {end_date},\"\n",
        "        f\"Start Date: {start_date}, Status: {status}, Title: {title},\"\n",
        "        f\"Goal: {goal}, Method: {method}, \"\n",
        "        f\"Generalized Goal: {generalized_goal}, Generalized Method: {generalized_method}, Tech Domain: {tech_domain}, \"\n",
        "        f\"Strategic Method: {strategic_method}, Standardized Domain Area: {standardized_domain_area}, \"\n",
        "        f\"Standardized Method Area: {standardized_method_area}, Final Domain: {final_domain}, Final Method: {final_method}, \"\n",
        "        f\"Broad Domain: {broad_domain}, Broad Method: {broad_method}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "CQZ_ucwYGM_3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_chroma_db(documents: list, ids: list, embedding_function_instance: embedding_functions.EmbeddingFunction):\n",
        "    \"\"\"\n",
        "    Sets up ChromaDB, creates or gets a collection, and adds documents.\n",
        "    \"\"\"\n",
        "    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
        "\n",
        "    # Use the Google Generative AI embedding function directly\n",
        "    # ChromaDB will use the configured genai.configure(api_key=...)\n",
        "    # We pass the model name to ensure consistency\n",
        "    embedding_func = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=GOOGLE_API_KEY, model_name=EMBEDDING_MODEL_NAME)\n",
        "\n",
        "    try:\n",
        "        collection = client.get_or_create_collection(\n",
        "            name=COLLECTION_NAME,\n",
        "            embedding_function=embedding_func # Use the configured embedding function\n",
        "        )\n",
        "        print(f\"Collection '{COLLECTION_NAME}' created or retrieved.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting/creating collection: {e}\")\n",
        "        # If collection exists with different embedding function, delete and recreate\n",
        "        try:\n",
        "            client.delete_collection(name=COLLECTION_NAME)\n",
        "            collection = client.get_or_create_collection(\n",
        "                name=COLLECTION_NAME,\n",
        "                embedding_function=embedding_func\n",
        "            )\n",
        "            print(f\"Collection '{COLLECTION_NAME}' deleted and recreated with new embedding function.\")\n",
        "        except Exception as e:\n",
        "            print(f\"FATAL: Could not get or create collection. Error: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Check if data already exists to avoid re-embedding everything on every run\n",
        "    if collection.count() < len(documents):\n",
        "        print(f\"Adding {len(documents)} documents to ChromaDB. This may take a while for 100k rows...\")\n",
        "        batch_size = 500 # Adjust batch size based on your system's memory and API rate limits\n",
        "        for i in range(0, len(documents), batch_size):\n",
        "            batch_docs = documents[i:i + batch_size]\n",
        "            batch_ids = ids[i:i + batch_size]\n",
        "            try:\n",
        "                collection.add(\n",
        "                    documents=batch_docs,\n",
        "                    ids=batch_ids\n",
        "                )\n",
        "                print(f\"Added batch {i//batch_size + 1}/{(len(documents)//batch_size)+1}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error adding batch starting at index {i}: {e}\")\n",
        "                # You might want to implement retry logic here\n",
        "\n",
        "        print(\"Finished adding documents to ChromaDB.\")\n",
        "    else:\n",
        "        print(f\"ChromaDB already contains {collection.count()} documents. Skipping embedding.\")\n",
        "\n",
        "    return collection"
      ],
      "metadata": {
        "id": "mPyK12cmGNj7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_info(query: str, collection, top_k: int = TOP_K_RESULTS) -> list:\n",
        "    \"\"\"\n",
        "    Retrieves the most relevant documents from ChromaDB based on a query.\n",
        "    \"\"\"\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    # results['documents'][0] contains the actual text content of the retrieved chunks\n",
        "    return results['documents'][0] if results and results['documents'] else []"
      ],
      "metadata": {
        "id": "Qjh4x5mNGQA_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rag_prompt(user_query: str, retrieved_context_current: list, conversation_history_genai_format: list = None) -> str:\n",
        "    \"\"\"\n",
        "    Constructs the prompt for the Gemini model, incorporating retrieved context and conversation history.\n",
        "    The conversation_history_genai_format is expected to be a list of GenAI content objects.\n",
        "    \"\"\"\n",
        "    context_str_current = \"\\n\".join([f\"- {doc}\" for doc in retrieved_context_current])\n",
        "    if not context_str_current:\n",
        "        context_str_current = \"No specific relevant information found for the current query.\"\n",
        "\n",
        "    history_str = \"\"\n",
        "    if conversation_history_genai_format:\n",
        "        history_str = \"\\n--- Conversation History ---\\n\"\n",
        "        for turn in conversation_history_genai_format:\n",
        "            role = turn.get('role', 'unknown').capitalize()\n",
        "            text_content = \"\"\n",
        "            for part in turn.get('parts', []):\n",
        "                if 'text' in part:\n",
        "                    text_content += part['text'] + \" \"\n",
        "\n",
        "            history_str += f\"{role}: {text_content.strip()}\\n\"\n",
        "        history_str += \"--------------------------\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert assistant designed to answer questions about projects funded by the European Commission (EC).\n",
        "    Your knowledge base includes details on institutions, countries, cultural distances, and specific project data.\n",
        "    All project information is structured as 'Column Name: Value' pairs.\n",
        "\n",
        "    --- Conversation History ---\n",
        "    {history_str}\n",
        "    --- End Conversation History ---\n",
        "\n",
        "    --- Relevant Project Data (from RAG search for current query) ---\n",
        "    {context_str_current}\n",
        "    --- End Relevant Project Data ---\n",
        "\n",
        "    Instructions:\n",
        "    1.  **Prioritize Tools:** If a user's question requires a specific lookup, count, or calculation (e.g., \"highest contribution,\" \"projects in X city,\" \"info on project ID Y\"), you **must** call the appropriate tool.\n",
        "    2.  **Use Provided Data (RAG Context):** For general questions or those not covered by tools, use the \"Relevant Project Data\" provided above.\n",
        "    3.  **State Limitations:** If the answer is not available in the provided data or through any available tool, clearly state that you do not have sufficient information to answer the question.\n",
        "    4.  **Be Concise and Factual:** Provide direct answers without fabricating information.\n",
        "\n",
        "    ---\n",
        "    {context_str_current}\n",
        "    ---\n",
        "\n",
        "    Question: {user_query}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "cn1Ql3tfGR3U"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some query functions"
      ],
      "metadata": {
        "id": "sh4SIzrN2tLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These functions will operate on your DataFrame (df)\n",
        "# We will pass df into these functions in the main loop\n",
        "# Ensure columns used in these functions exist and are clean in your actual CSV data.\n",
        "\n",
        "def get_projects_by_city(df: pd.DataFrame, city_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves a list of project IDs and organization names for projects located in a specified city.\n",
        "    Args:\n",
        "        df: The DataFrame containing project data.\n",
        "        city_name: The name of the city to filter by.\n",
        "    Returns:\n",
        "        A string summarizing projects found or a message if none.\n",
        "    \"\"\"\n",
        "    city_name = city_name.strip() # Clean input\n",
        "    filtered_df = df[df['city'].astype(str).str.contains(city_name, case=False, na=False)]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        return f\"No projects found in {city_name}.\"\n",
        "\n",
        "    project_info = []\n",
        "    for _, row in filtered_df.head(10).iterrows(): # Limit to first 10 for brevity\n",
        "        project_id = row.get('projectID', 'N/A')\n",
        "        org_name = row.get('name', 'N/A')\n",
        "        project_info.append(f\"Project ID: {project_id}, Org: {org_name}\")\n",
        "\n",
        "    total_count = len(filtered_df)\n",
        "    summary = f\"Found {total_count} projects in {city_name}. Here are some of them:\\n\" + \"\\n\".join(project_info)\n",
        "    if total_count > 10:\n",
        "        summary += f\"\\n...and {total_count - 10} more.\"\n",
        "    return summary"
      ],
      "metadata": {
        "id": "bv2MnZUs2slW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_projects_by_city(df: pd.DataFrame, city_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Counts the number of projects located in a specified city.\n",
        "    Args:\n",
        "        df: The DataFrame containing project data.\n",
        "        city_name: The name of the city to count projects for.\n",
        "    Returns:\n",
        "        A string stating the count of projects.\n",
        "    \"\"\"\n",
        "    city_name = city_name.strip()\n",
        "    filtered_df = df[df['city'].astype(str).str.contains(city_name, case=False, na=False)]\n",
        "    count = len(filtered_df)\n",
        "    return f\"There are {count} projects in {city_name}.\""
      ],
      "metadata": {
        "id": "5spn-b7x2-CV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_highest_contribution_project(df: pd.DataFrame, year: int = None) -> str:\n",
        "    \"\"\"\n",
        "    Finds the project with the highest EC Contribution, optionally filtered by a specific year.\n",
        "    \"\"\"\n",
        "    temp_df = df.copy()\n",
        "\n",
        "    temp_df['ecContribution_numeric'] = pd.to_numeric(temp_df['ecContribution'], errors='coerce')\n",
        "    temp_df.dropna(subset=['ecContribution_numeric'], inplace=True)\n",
        "\n",
        "    if 'endDate' in temp_df.columns:\n",
        "        temp_df['end_year'] = pd.to_datetime(temp_df['endDate'], errors='coerce').dt.year\n",
        "        temp_df.dropna(subset=['end_year'], inplace=True)\n",
        "    else:\n",
        "        temp_df['end_year'] = None\n",
        "\n",
        "    if year is not None: # Check if year was provided\n",
        "        try:\n",
        "            year_int = int(year) # <--- Explicitly cast to integer here\n",
        "        except (ValueError, TypeError):\n",
        "            return \"Invalid year provided. Please provide a valid integer year.\"\n",
        "\n",
        "        if 'end_year' in temp_df.columns:\n",
        "            temp_df = temp_df[temp_df['end_year'] == year_int] # Compare with integer year\n",
        "        else:\n",
        "            return f\"Cannot filter by year {year_int}: 'endPeriod' column not found or invalid in data.\"\n",
        "\n",
        "    if temp_df.empty:\n",
        "        return f\"No projects found {'in ' + str(year_int) + ' with valid EC Contribution' if year else 'with valid EC Contribution'}.\" # Adjusted message for year_int\n",
        "\n",
        "    highest_contrib_project = temp_df.loc[temp_df['ecContribution_numeric'].idxmax()]\n",
        "\n",
        "    project_id = highest_contrib_project.get('projectID', 'N/A')\n",
        "    org_name = highest_contrib_project.get('name', 'N/A')\n",
        "    ec_contribution = highest_contrib_project.get('ecContribution_numeric', 'N/A')\n",
        "    city = highest_contrib_project.get('city', 'N/A')\n",
        "    country = highest_contrib_project.get('country', 'N/A')\n",
        "    end_year = int(highest_contrib_project.get('end_year', 'N/A')) if pd.notna(highest_contrib_project.get('end_year')) else 'N/A'\n",
        "\n",
        "    return (\n",
        "        f\"The project with the highest EC Contribution {'in ' + str(year_int) if year is not None else 'overall'} is:\\n\"\n",
        "        f\"Project ID: {project_id}\\n\"\n",
        "        f\"Organization: {org_name}\\n\"\n",
        "        f\"EC Contribution: {ec_contribution}\\n\"\n",
        "        f\"City: {city}\\n\"\n",
        "        f\"Country: {country}\\n\"\n",
        "        f\"End Year: {end_year}\" # CORRECTED: Reference End Year\n",
        "    )"
      ],
      "metadata": {
        "id": "Y7N0Bh5w3AJ4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_highest_contribution_by_country(df: pd.DataFrame, country_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Finds the project with the highest EC Contribution in a specified country.\n",
        "    Uses 'country' or 'Countryname' columns for filtering.\n",
        "    \"\"\"\n",
        "    temp_df = df.copy()\n",
        "    country_name_lower = country_name.strip().lower()\n",
        "\n",
        "    temp_df['ecContribution_numeric'] = pd.to_numeric(temp_df['ecContribution'], errors='coerce')\n",
        "    temp_df.dropna(subset=['ecContribution_numeric'], inplace=True)\n",
        "\n",
        "    # Filter by 'country' or 'Countryname'\n",
        "    filtered_df = temp_df[\n",
        "        (temp_df['country'].astype(str).str.lower() == country_name_lower) |\n",
        "        (temp_df['Countryname'].astype(str).str.lower().str.contains(country_name_lower, na=False))\n",
        "    ]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        return f\"No projects found with valid EC Contribution in {country_name}.\"\n",
        "\n",
        "    highest_contrib_project = filtered_df.loc[filtered_df['ecContribution_numeric'].idxmax()]\n",
        "\n",
        "    project_id = highest_contrib_project.get('projectID', 'N/A')\n",
        "    project_name = highest_contrib_project.get('name', 'N/A')\n",
        "    ec_contribution = highest_contrib_project.get('ecContribution_numeric', 'N/A')\n",
        "    city = highest_contrib_project.get('city', 'N/A')\n",
        "    country_found = highest_contrib_project.get('country', highest_contrib_project.get('Countryname', 'N/A'))\n",
        "\n",
        "    return (\n",
        "        f\"The project with the highest EC Contribution in {country_found} is:\\n\"\n",
        "        f\"Project ID: {project_id}\\n\"\n",
        "        f\"Institution Name: {project_name}\\n\"\n",
        "        f\"EC Contribution: {ec_contribution}\\n\"\n",
        "        f\"City: {city}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "x4F9CGgoqjg0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_project_info_by_id(df: pd.DataFrame, project_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves detailed information for a project given its project ID.\n",
        "    \"\"\"\n",
        "    # Ensure projectID column is treated as string for consistent comparison\n",
        "    temp_df = df.copy()\n",
        "    temp_df['projectID'] = temp_df['projectID'].astype(str)\n",
        "\n",
        "    filtered_df = temp_df[temp_df['projectID'] == str(project_id).strip()]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        return f\"No project found with ID: {project_id}.\"\n",
        "\n",
        "    project_info = filtered_df.iloc[0] # Get the first (and hopefully only) matching row\n",
        "\n",
        "    # Format the output with relevant details\n",
        "    output = f\"Project Details for ID: {project_info.get('projectID', 'N/A')}\\n\"\n",
        "    output += f\"  Name: {project_info.get('name', 'N/A')}\\n\"\n",
        "    output += f\"  Title: {project_info.get('title', 'N/A')}\\n\"\n",
        "    output += f\"  Status: {project_info.get('status', 'N/A')}\\n\"\n",
        "    output += f\"  EC Contribution: {project_info.get('ecContribution', 'N/A')}\\n\"\n",
        "    output += f\"  Net EC Contribution: {project_info.get('netEcContribution', 'N/A')}\\n\"\n",
        "    output += f\"  Total Cost: {project_info.get('totalCost_x', 'N/A')}\\n\"\n",
        "    output += f\"  Max EC Contribution: {project_info.get('ecMaxContribution', 'N/A')}\\n\"\n",
        "    output += f\"  Country: {project_info.get('Countryname', project_info.get('country', 'N/A'))}\\n\"\n",
        "    output += f\"  City: {project_info.get('city', 'N/A')}\\n\"\n",
        "    output += f\"  Start Date: {project_info.get('startDate', 'N/A')}\\n\"\n",
        "    output += f\"  End Date: {project_info.get('endDate', 'N/A')}\\n\"\n",
        "    output += f\"  Role: {project_info.get('role', 'N/A')}\\n\"\n",
        "    output += f\"  Goal: {project_info.get('goal', 'N/A')}\\n\"\n",
        "    output += f\"  Method: {project_info.get('method', 'N/A')}\\n\"\n",
        "    output += f\"  Tech Domain: {project_info.get('tech_domain', 'N/A')}\\n\"\n",
        "    output += f\"  Organization URL: {project_info.get('organizationURL', 'N/A')}\\n\"\n",
        "    output += f\"  Geolocation: {project_info.get('geolocation', 'N/A')}\\n\"\n",
        "    # You can add more fields from your extensive list as needed.\n",
        "    return output"
      ],
      "metadata": {
        "id": "RJ0j8Lzst70w"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- NEW: Define tools for Gemini ---\n",
        "# These are the declarations that Gemini will use to understand when to call your functions.\n",
        "# Ensure the names, descriptions, and parameters match your Python functions.\n",
        "tools = [\n",
        "    Tool(\n",
        "        function_declarations=[\n",
        "            protos.FunctionDeclaration(\n",
        "                name='get_projects_by_city',\n",
        "                description='Retrieves a list of project IDs and project names for projects in a specified city.',\n",
        "                parameters=protos.Schema(\n",
        "                    type=protos.Type.OBJECT,\n",
        "                    properties={\n",
        "                        'city_name': protos.Schema(type=protos.Type.STRING, description='The name of the city (e.g., \"London\", \"Paris\").'),\n",
        "                    },\n",
        "                    required=['city_name'],\n",
        "                ),\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    Tool(\n",
        "        function_declarations=[\n",
        "            protos.FunctionDeclaration(\n",
        "                name='count_projects_by_city',\n",
        "                description='Counts the total number of projects located in a specified city.',\n",
        "                parameters=protos.Schema(\n",
        "                    type=protos.Type.OBJECT,\n",
        "                    properties={\n",
        "                        'city_name': protos.Schema(type=protos.Type.STRING, description='The name of the city to count projects for (e.g., \"London\", \"Paris\").'),\n",
        "                    },\n",
        "                    required=['city_name'],\n",
        "                ),\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    Tool(\n",
        "        function_declarations=[\n",
        "            protos.FunctionDeclaration(\n",
        "                name='get_highest_contribution_project',\n",
        "                description='Finds the project with the highest European Commission (EC) Contribution. Can optionally filter by end year.',\n",
        "                parameters=protos.Schema(\n",
        "                    type=protos.Type.OBJECT,\n",
        "                    properties={\n",
        "                        'year': protos.Schema(type=protos.Type.INTEGER, description='Optional: The specific year to filter projects by. For example, 2021.'),\n",
        "                    },\n",
        "                    required=[],\n",
        "                ),\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    Tool(\n",
        "        function_declarations=[\n",
        "            protos.FunctionDeclaration(\n",
        "                name='get_highest_contribution_by_country',\n",
        "                description='Finds the project with the highest European Commission (EC) Contribution in a specified country.',\n",
        "                parameters=protos.Schema(\n",
        "                    type=protos.Type.OBJECT,\n",
        "                    properties={\n",
        "                        'country_name': protos.Schema(type=protos.Type.STRING, description='The name or code of the country (e.g., \"Germany\", \"DE\", \"France\").'),\n",
        "                    },\n",
        "                    required=['country_name'],\n",
        "                ),\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    Tool(\n",
        "        function_declarations=[\n",
        "            protos.FunctionDeclaration(\n",
        "                name='get_project_info_by_id',\n",
        "                description='Retrieves detailed information about a project given its unique project ID.',\n",
        "                parameters=protos.Schema(\n",
        "                    type=protos.Type.OBJECT,\n",
        "                    properties={\n",
        "                        'project_id': protos.Schema(type=protos.Type.STRING, description='The unique ID of the project (e.g., \"101113245\").'),\n",
        "                    },\n",
        "                    required=['project_id'],\n",
        "                ),\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "5s1qv9wH3GLz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_history_for_chat(history_list: list):\n",
        "    formatted_chat_history = []\n",
        "    for turn in history_list:\n",
        "        # User messages\n",
        "        formatted_chat_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [{\"text\": turn[\"user_query\"]}]\n",
        "        })\n",
        "        # Assistant messages\n",
        "        formatted_chat_history.append({\n",
        "            \"role\": \"model\",\n",
        "            \"parts\": [{\"text\": turn[\"assistant_response\"]}]\n",
        "        })\n",
        "    return formatted_chat_history"
      ],
      "metadata": {
        "id": "4CUDgJncnLGt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # --- Load Data ---\n",
        "    print(f\"Loading data from {CSV_FILE_PATH}...\")\n",
        "    try:\n",
        "        # Using nrows=400 as indicated by the user for testing\n",
        "        df = pd.read_csv(CSV_FILE_PATH, sep=',', nrows=400)\n",
        "        print(f\"Loaded {len(df)} rows.\")\n",
        "        if 'projectID' not in df.columns:\n",
        "            df['projectID'] = df.index # Use row index as ID if 'projectID' column is missing\n",
        "            print(\"Warning: 'projectID' column not found, using row index as ID.\")\n",
        "\n",
        "        # Ensure numeric columns are numeric, converting errors to NaN\n",
        "        df['ecContribution'] = pd.to_numeric(df['ecContribution'], errors='coerce')\n",
        "        df['netEcContribution'] = pd.to_numeric(df['netEcContribution'], errors='coerce')\n",
        "        df['totalCost_x'] = pd.to_numeric(df['totalCost_x'], errors='coerce')\n",
        "        df['ecMaxContribution'] = pd.to_numeric(df['ecMaxContribution'], errors='coerce')\n",
        "\n",
        "        # Ensure date columns are datetime objects\n",
        "        df['endDate'] = pd.to_datetime(df['endDate'], errors='coerce')\n",
        "        df['startDate'] = pd.to_datetime(df['startDate'], errors='coerce')\n",
        "        df['contentUpdateDate_x'] = pd.to_datetime(df['contentUpdateDate_x'], errors='coerce')\n",
        "        df['ecSignatureDate'] = pd.to_datetime(df['ecSignatureDate'], errors='coerce')\n",
        "\n",
        "        # Fill N/A for string columns that are used in filtering if they might be missing\n",
        "        for col in ['city', 'country', 'Countryname', 'name', 'title', 'projectID']: # Added projectID here for safety\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('').astype(str) # Fill NaN with empty string and ensure string type\n",
        "            else:\n",
        "                df[col] = '' # Create empty column if not present for consistency\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {CSV_FILE_PATH} not found.\")\n",
        "        print(\"Please create a dummy CSV or provide the correct path to your 100k row CSV.\")\n",
        "        print(\"Creating a small dummy CSV for demonstration purposes...\")\n",
        "\n",
        "        dummy_data = {\n",
        "            'projectID': [f'P{i:05d}' for i in range(100)],\n",
        "            'name': [f'Project Name {i}' for i in range(100)],\n",
        "            'title': [f'Project Title {i} (A Study on {i%5})' for i in range(100)],\n",
        "            'city': ['London' if i % 5 == 0 else 'Paris' if i % 5 == 1 else 'Berlin' if i % 5 == 2 else 'Rome' if i % 5 == 3 else 'Madrid' for i in range(100)],\n",
        "            'country': ['UK' if i % 5 == 0 else 'FR' if i % 5 == 1 else 'DE' if i % 5 == 2 else 'IT' if i % 5 == 3 else 'ES' for i in range(100)],\n",
        "            'Countryname': ['United Kingdom' if i % 5 == 0 else 'France' if i % 5 == 1 else 'Germany' if i % 5 == 2 else 'Italy' if i % 5 == 3 else 'Spain' for i in range(100)],\n",
        "            'ecContribution': [str(100000 + i * 1000) for i in range(100)],\n",
        "            'netEcContribution': [str(90000 + i * 900) for i in range(100)],\n",
        "            'totalCost_x': [str(200000 + i * 1500) for i in range(100)],\n",
        "            'ecMaxContribution': [str(120000 + i * 1100) for i in range(100)],\n",
        "            'endDate': [f'202{(i%5)+1}-12-31' for i in range(100)],\n",
        "            'startDate': [f'202{(i%5)}-01-01' for i in range(100)],\n",
        "            'status': ['Closed' if i % 2 == 0 else 'Open' for i in range(100)],\n",
        "            'goal': [f'Goal {i}' for i in range(100)],\n",
        "            'method': [f'Method {i}' for i in range(100)],\n",
        "            'geolocation': [f'{50 + i/100},{10 + i/100}' for i in range(100)],\n",
        "            'postCode': [f'PC{i}' for i in range(100)],\n",
        "            'street': [f'Street {i}' for i in range(100)],\n",
        "            'contactForm': [f'Form{i}' for i in range(100)],\n",
        "            'organizationURL': [f'http://org{i}.com' for i in range(100)],\n",
        "            'contentUpdateDate_x': [f'202{(i%5)+1}-01-01' for i in range(100)],\n",
        "            'ecSignatureDate': [f'202{(i%5)+1}-03-15' for i in range(100)],\n",
        "            'cultdist': [str(0.5 + i/1000) for i in range(100)],\n",
        "            'cultdist_std': [str(0.1 + i/2000) for i in range(100)],\n",
        "            'role': ['Coordinator' if i % 4 == 0 else 'Partner' for i in range(100)],\n",
        "            'generalized_goal': [f'Gen Goal {i%3}' for i in range(100)],\n",
        "            'generalized_method': [f'Gen Method {i%3}' for i in range(100)],\n",
        "            'tech_domain': [f'Tech Domain {i%4}' for i in range(100)],\n",
        "            'strategic_method': [f'Strat Method {i%2}' for i in range(100)],\n",
        "            'standardized_domain_area': [f'Std Domain {i%5}' for i in range(100)],\n",
        "            'standardized_method_area': [f'Std Method {i%5}' for i in range(100)],\n",
        "            'final_domain': [f'Final Domain {i%2}' for i in range(100)],\n",
        "            'final_method': [f'Final Method {i%2}' for i in range(100)],\n",
        "            'broad_domain': [f'Broad Domain {i%3}' for i in range(100)],\n",
        "            'broad_method': [f'Broad Method {i%3}' for i in range(100)],\n",
        "        }\n",
        "        df = pd.DataFrame(dummy_data)\n",
        "        df.to_csv(CSV_FILE_PATH, index=False)\n",
        "        print(f\"Created dummy CSV file: {CSV_FILE_PATH} with {len(df)} rows.\")\n",
        "\n",
        "        # Re-apply type conversions for dummy data\n",
        "        df['ecContribution'] = pd.to_numeric(df['ecContribution'], errors='coerce')\n",
        "        df['netEcContribution'] = pd.to_numeric(df['netEcContribution'], errors='coerce')\n",
        "        df['totalCost_x'] = pd.to_numeric(df['totalCost_x'], errors='coerce')\n",
        "        df['ecMaxContribution'] = pd.to_numeric(df['ecMaxContribution'], errors='coerce')\n",
        "\n",
        "        df['endDate'] = pd.to_datetime(df['endDate'], errors='coerce')\n",
        "        df['startDate'] = pd.to_datetime(df['startDate'], errors='coerce')\n",
        "        df['contentUpdateDate_x'] = pd.to_datetime(df['contentUpdateDate_x'], errors='coerce')\n",
        "        df['ecSignatureDate'] = pd.to_datetime(df['ecSignatureDate'], errors='coerce')\n",
        "\n",
        "        # Fill N/A for string columns for dummy data as well\n",
        "        for col in ['city', 'country', 'Countryname', 'name', 'title', 'projectID']:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('').astype(str) # Fill NaN with empty string and ensure string type\n",
        "\n",
        "\n",
        "    # Prepare documents for ChromaDB\n",
        "    documents = [create_text_from_row(row) for index, row in df.iterrows()]\n",
        "    ids = [f\"{str(row['projectID'])}_{index}\" for index, row in df.iterrows()]\n",
        "\n",
        "    # --- Setup ChromaDB ---\n",
        "    print(\"Setting up ChromaDB...\")\n",
        "    google_embedding_function = embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
        "        api_key=GOOGLE_API_KEY, model_name=EMBEDDING_MODEL_NAME\n",
        "    )\n",
        "    collection = setup_chroma_db(documents, ids, google_embedding_function)\n",
        "\n",
        "    if collection is None:\n",
        "        print(\"Failed to set up ChromaDB. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # --- Initialize Gemini for Generation with Tools ---\n",
        "    generation_model = genai.GenerativeModel(GENERATION_MODEL_NAME, tools=tools)\n",
        "    print(f\"Initialized Gemini model: {GENERATION_MODEL_NAME} with tools.\")\n",
        "\n",
        "    # This 'conversation_history_for_rag' will be for *our* manual tracking and building RAG prompt history,\n",
        "    # NOT directly for `start_chat` unless formatted.\n",
        "    conversation_history_for_rag = []\n",
        "\n",
        "    print(\"\\nChatbot is ready! Ask questions about your project data.\")\n",
        "    print(\"Try: 'How many projects are in London?', 'What is the highest paid project?', 'What is the highest paid project in 2024?'\")\n",
        "    print(\"NEW: 'What is the highest paid project in Germany?', 'Tell me about project P00001'\")\n",
        "    print(\"Type 'exit' or 'quit' to end the session.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nYour question: \").strip()\n",
        "        if user_query.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Format history for start_chat at the beginning of each turn\n",
        "        # This will convert our simple dicts to the required role/parts format\n",
        "        formatted_chat_history = format_history_for_chat(conversation_history_for_rag)\n",
        "        chat_session = generation_model.start_chat(history=formatted_chat_history)\n",
        "\n",
        "        assistant_response = \"I encountered an error.\" # Default in case of issues\n",
        "        retrieved_context_current = [] # Initialize for current turn\n",
        "\n",
        "        try:\n",
        "            # Send the user's message to the chat session\n",
        "            response = chat_session.send_message(user_query)\n",
        "\n",
        "            # --- Tool Call Handling Logic ---\n",
        "            # This handles a single tool call and its response, or a text response.\n",
        "\n",
        "            if response.candidates and response.candidates[0].content.parts[0].function_call:\n",
        "                tool_call = response.candidates[0].content.parts[0].function_call\n",
        "                tool_name = tool_call.name\n",
        "                tool_args = {k: v for k, v in tool_call.args.items()}\n",
        "\n",
        "                print(f\"Tool Call detected: {tool_name} with args {tool_args}\")\n",
        "\n",
        "                tool_output = None\n",
        "                try:\n",
        "                    if tool_name == 'get_projects_by_city':\n",
        "                        tool_output = get_projects_by_city(df, **tool_args)\n",
        "                    elif tool_name == 'count_projects_by_city':\n",
        "                        tool_output = count_projects_by_city(df, **tool_args)\n",
        "                    elif tool_name == 'get_highest_contribution_project':\n",
        "                        tool_output = get_highest_contribution_project(df, **tool_args)\n",
        "                    elif tool_name == 'get_highest_contribution_by_country':\n",
        "                        tool_output = get_highest_contribution_by_country(df, **tool_args)\n",
        "                    elif tool_name == 'get_project_info_by_id': # Handle new tool\n",
        "                        tool_output = get_project_info_by_id(df, **tool_args)\n",
        "                    else:\n",
        "                        tool_output = f\"Error: Unknown tool_code function: {tool_name}\"\n",
        "\n",
        "                    print(f\"Tool Output: {tool_output}\")\n",
        "\n",
        "                    # Send the tool output back to the *same chat session*\n",
        "                    tool_response_payload = {\n",
        "                        \"parts\": [\n",
        "                            {\n",
        "                                \"function_response\": {\n",
        "                                    \"name\": tool_name,\n",
        "                                    \"response\": {\"result\": tool_output}\n",
        "                                }\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                    # Get the model's response AFTER receiving the tool output\n",
        "                    final_model_response_after_tool = chat_session.send_message(tool_response_payload)\n",
        "\n",
        "                    # --- Handle model's response after tool execution ---\n",
        "                    if final_model_response_after_tool.candidates and final_model_response_after_tool.candidates[0].content:\n",
        "                        first_part = final_model_response_after_tool.candidates[0].content.parts[0]\n",
        "\n",
        "                        if hasattr(first_part, 'text'): # It's a text response\n",
        "                            assistant_response = first_part.text\n",
        "                        elif hasattr(first_part, 'function_call'): # It's another tool call (chained call)\n",
        "                            chained_tool_call = first_part.function_call\n",
        "                            assistant_response = (f\"Model requested another tool call: {chained_tool_call.name} \"\n",
        "                                                  f\"with args {chained_tool_call.args}. \"\n",
        "                                                  f\"The system is not yet set up for recursive tool calls in this scenario. \"\n",
        "                                                  f\"Please rephrase your question or consider extending the tool handling logic.\")\n",
        "                        else:\n",
        "                            assistant_response = \"Model returned an unrecognized content type after tool execution.\"\n",
        "                    else:\n",
        "                        assistant_response = \"Model did not return valid content after tool execution.\"\n",
        "\n",
        "                except Exception as tool_e:\n",
        "                    assistant_response = f\"An error occurred while executing the tool ({tool_name}): {tool_e}\"\n",
        "                    print(assistant_response)\n",
        "\n",
        "            else:\n",
        "                # No tool call from the model, so proceed with RAG\n",
        "                print(f\"Searching for relevant information for: '{user_query}'...\")\n",
        "                retrieved_context_current = retrieve_relevant_info(user_query, collection, TOP_K_RESULTS)\n",
        "                print(retrieved_context_current)\n",
        "\n",
        "                if not retrieved_context_current:\n",
        "                    print(\"No relevant context found for current query. Answering based on history or general knowledge.\")\n",
        "\n",
        "                final_rag_prompt = build_rag_prompt(user_query, retrieved_context_current, conversation_history_for_rag)\n",
        "\n",
        "                # Send the RAG prompt *to the chat session*\n",
        "                rag_response = chat_session.send_message(final_rag_prompt)\n",
        "                assistant_response = rag_response.text\n",
        "\n",
        "            print(\"\\nChatbot:\", assistant_response)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response from Gemini: {e}\")\n",
        "            print(\"Please check your API key, model limits, or prompt content.\")\n",
        "            assistant_response = \"I encountered an error trying to generate a response.\"\n",
        "\n",
        "        # --- Update conversation_history_for_rag for next loop iteration ---\n",
        "        # Truncate history (both user and model turns) if it exceeds MAX_HISTORY_TURNS\n",
        "        if len(conversation_history_for_rag) >= MAX_HISTORY_TURNS:\n",
        "            conversation_history_for_rag.pop(0)\n",
        "\n",
        "        # Append the current user query and assistant response for future RAG prompt building\n",
        "        conversation_history_for_rag.append({\n",
        "            \"user_query\": user_query,\n",
        "            \"assistant_response\": assistant_response,\n",
        "            \"retrieved_context\": retrieved_context_current\n",
        "        })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rJsNASgIGTkc",
        "outputId": "7fa1138d-88fa-48d9-8328-6b5fee1d313a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/My Drive/MDA/merged_organization_project_data.csv...\n",
            "Loaded 400 rows.\n",
            "Setting up ChromaDB...\n",
            "Collection 'project_data' created or retrieved.\n",
            "ChromaDB already contains 400 documents. Skipping embedding.\n",
            "Initialized Gemini model: gemini-1.5-pro with tools.\n",
            "\n",
            "Chatbot is ready! Ask questions about your project data.\n",
            "Try: 'How many projects are in London?', 'What is the highest paid project?', 'What is the highest paid project in 2024?'\n",
            "NEW: 'What is the highest paid project in Germany?', 'Tell me about project P00001'\n",
            "Type 'exit' or 'quit' to end the session.\n",
            "\n",
            "Your question: What is the cultural distince between Germany and Austria?\n",
            "Searching for relevant information for: 'What is the cultural distince between Germany and Austria?'...\n",
            "['City: Wien, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/901064817/101130898, Content Update Date: 2023-10-13 14:41:04, Country: AT, EC Contribution: 258312.5, Geolocation: 48.1738894,16.3884609, Name: CEU GMBH, Net EC Contribution: 258312.5, Organization URL: nan, Post Code: 1100, Project ID: 101130898, Role: participant, Street: QUELLENSTRASSE 51, Total Cost of the project: 258312.5, Cultural Distance: 0.33304018, Cultural Distance Std: -0.15716016, Country Name: Austria,EC Max Contribution: 1999250.0, EC Signature Date: 2023-09-28, End Date: 2027-02-28 00:00:00,Start Date: 2024-03-01, Status: SIGNED, Title: Advancing the zero-tolerance approach to gender-based violence in higher education and research in the European Research Area,Goal: Safe research environments for all genders, Method: Capacity building & Policy Monitoring, Generalized Goal: Safe Research Environments, Generalized Method: N/A, Tech Domain: Gender Equality Studies, Strategic Method: Societal Impact Analysis, Standardized Domain Area: Social & Political Studies, Standardized Method Area: Policy Analysis & Formulation, Final Domain: Social Sciences & Human Behavior, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Policy/ Governance & Law, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Bonn, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/915816092/101058094, Content Update Date: 2022-09-12 16:13:08, Country: DE, EC Contribution: 424857.5, Geolocation: 52.0754038,9.329585, Name: EUREC OFFICE GUG, Net EC Contribution: 424857.5, Organization URL: nan, Post Code: 53225, Project ID: 101058094, Role: participant, Street: WERDSTR. 31, Total Cost of the project: 424857.5, Cultural Distance: 0.33376053, Cultural Distance Std: -0.12619418, Country Name: Germany,EC Max Contribution: 4201758.75, EC Signature Date: 2022-05-11, End Date: 2025-08-31 00:00:00,Start Date: 2022-09-01, Status: SIGNED, Title: Pro-active Pandemic Crisis Ethics and Integrity Framework,Goal: Prepare for ethical pandemic research response, Method: International Ethics & Integrity Framework, Generalized Goal: Pandemic Preparedness & Ethics, Generalized Method: N/A, Tech Domain: Public Health Ethics, Strategic Method: Crisis Management Protocols, Standardized Domain Area: Public Health Ethics, Standardized Method Area: Crisis Management Protocols, Final Domain: Policy, Governance & Law, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Langen, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/998217301/101103241, Content Update Date: 2023-07-20 12:20:57, Country: DE, EC Contribution: 0.0, Geolocation: 50.00627535,8.64854167508377, Name: BUNDESINSTITUT FUR IMPFSTOFFE UND BIOMEDIZINISCHE ARZNEIMITTEL, Net EC Contribution: 0.0, Organization URL: http://www.pei.de, Post Code: 63225, Project ID: 101103241, Role: participant, Street: PAUL-EHRLICH-STRASSE  51-59, Total Cost of the project: 0.0, Cultural Distance: 0.33376053, Cultural Distance Std: -0.12619418, Country Name: Germany,EC Max Contribution: 514961.25, EC Signature Date: 2023-06-01, End Date: 2025-05-31 00:00:00,Start Date: 2023-06-01, Status: SIGNED, Title: Practical strengthening of regulatory and ethics oversight on clinical trials in West Africa using Lassa Fever vaccine development projects and increase regulatory maturity level in targeted countries,Goal: Strengthen clinical trial oversight in West Africa, Method: Practical training in vaccine development, Generalized Goal: Clinical Trial Oversight, Generalized Method: N/A, Tech Domain: Clinical Research Ethics, Strategic Method: Regulatory Capacity Building, Standardized Domain Area: Clinical Research Governance, Standardized Method Area: Capacity Building & Training Delivery, Final Domain: Drug Discovery & Pharmaceutical Sciences, Final Method: Capacity Building & Training, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Communication, Collaboration & Knowledge Exchange', 'City: Basel, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/935811478/101058094, Content Update Date: 2022-09-12 16:13:08, Country: CH, EC Contribution: nan, Geolocation: 47.5594078,7.58043379178956, Name: STIFTUNG GLOBALE WERTE ALLIANZ, Net EC Contribution: 0.0, Organization URL: nan, Post Code: 4056, Project ID: 101058094, Role: associatedPartner, Street: Schoenbeinstrasse 23, Total Cost of the project: 0.0, Cultural Distance: 0.3474654, Cultural Distance Std: 0.45683578, Country Name: Switzerland,EC Max Contribution: 4201758.75, EC Signature Date: 2022-05-11, End Date: 2025-08-31 00:00:00,Start Date: 2022-09-01, Status: SIGNED, Title: Pro-active Pandemic Crisis Ethics and Integrity Framework,Goal: Prepare for ethical pandemic research response, Method: International Ethics & Integrity Framework, Generalized Goal: Pandemic Preparedness & Ethics, Generalized Method: N/A, Tech Domain: Public Health Ethics, Strategic Method: Crisis Management Protocols, Standardized Domain Area: Public Health Ethics, Standardized Method Area: Crisis Management Protocols, Final Domain: Policy, Governance & Law, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Muenster, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/999882888/101073949, Content Update Date: 2022-09-15 14:27:22, Country: DE, EC Contribution: 183566.0, Geolocation: 51.9501317,7.61330165026119, Name: DEUTSCHE HOCHSCHULE DER POLIZEI, Net EC Contribution: 183566.0, Organization URL: http://www.pfa.nrw.de, Post Code: 48165, Project ID: 101073949, Role: participant, Street: Zum Roten Berge 18-24, Total Cost of the project: 183566.25, Cultural Distance: 0.33376053, Cultural Distance Std: -0.12619418, Country Name: Germany,EC Max Contribution: 2410865.5, EC Signature Date: 2022-07-22, End Date: 2025-09-30 00:00:00,Start Date: 2022-10-01, Status: SIGNED, Title: 2PS - Prevent & Protect Through Support,Goal: Prevent online child sexual abuse., Method: Support for proactive prevention strategies., Generalized Goal: Child Safety Online, Generalized Method: N/A, Tech Domain: Digital Security & Safety, Strategic Method: Online Harm Prevention, Standardized Domain Area: Digital Safety, Standardized Method Area: Prevention Strategies, Final Domain: Social Sciences & Human Behavior, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Society, Culture, Broad Method: Innovation, Strategic Management & Evaluation Methods']\n",
            "\n",
            "Chatbot: Based on the provided data, the cultural distance score for Germany is 0.33376053 and for Austria it is 0.33304018.  I do not have information on what these scores represent or how they were calculated, so I cannot interpret the cultural distance between the two countries.\n",
            "\n",
            "\n",
            "Your question: 'What is the highest paid project?'\n",
            "Tool Call detected: get_highest_contribution_project with args {}\n",
            "Tool Output: The project with the highest EC Contribution overall is:\n",
            "Project ID: 101126531\n",
            "Organization: COALITION FOR EPIDEMIC PREPAREDNESS INNOVATIONS\n",
            "EC Contribution: 70000000.0\n",
            "City: Oslo\n",
            "Country: NO\n",
            "End Year: 2028\n",
            "\n",
            "Chatbot: The project with the highest EC Contribution is project ID 101126531, COALITION FOR EPIDEMIC PREPAREDNESS INNOVATIONS, with an EC contribution of 70,000,000.0, located in Oslo, Norway. The project is expected to end in 2028.\n",
            "\n",
            "\n",
            "Your question: What topics does this project deal with?\n",
            "Searching for relevant information for: 'What topics does this project deal with?'...\n",
            "['City: Paris, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/999454245/101058094, Content Update Date: 2022-09-12 16:13:08, Country: FR, EC Contribution: 141657.5, Geolocation: 48.8504357,2.3067152, Name: UNITED NATIONS EDUCATIONAL SCIENTIFIC AND CULTURAL ORGANIZATION, Net EC Contribution: 141657.5, Organization URL: http://www.unesco.org, Post Code: 75007, Project ID: 101058094, Role: participant, Street: PLACE DE FONTENOY 7, Total Cost of the project: 141657.5, Cultural Distance: 0.3380003, Cultural Distance Std: 0.055394657, Country Name: France,EC Max Contribution: 4201758.75, EC Signature Date: 2022-05-11, End Date: 2025-08-31 00:00:00,Start Date: 2022-09-01, Status: SIGNED, Title: Pro-active Pandemic Crisis Ethics and Integrity Framework,Goal: Prepare for ethical pandemic research response, Method: International Ethics & Integrity Framework, Generalized Goal: Pandemic Preparedness & Ethics, Generalized Method: N/A, Tech Domain: Public Health Ethics, Strategic Method: Crisis Management Protocols, Standardized Domain Area: Public Health Ethics, Standardized Method Area: Crisis Management Protocols, Final Domain: Policy, Governance & Law, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Bonn, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/915816092/101058094, Content Update Date: 2022-09-12 16:13:08, Country: DE, EC Contribution: 424857.5, Geolocation: 52.0754038,9.329585, Name: EUREC OFFICE GUG, Net EC Contribution: 424857.5, Organization URL: nan, Post Code: 53225, Project ID: 101058094, Role: participant, Street: WERDSTR. 31, Total Cost of the project: 424857.5, Cultural Distance: 0.33376053, Cultural Distance Std: -0.12619418, Country Name: Germany,EC Max Contribution: 4201758.75, EC Signature Date: 2022-05-11, End Date: 2025-08-31 00:00:00,Start Date: 2022-09-01, Status: SIGNED, Title: Pro-active Pandemic Crisis Ethics and Integrity Framework,Goal: Prepare for ethical pandemic research response, Method: International Ethics & Integrity Framework, Generalized Goal: Pandemic Preparedness & Ethics, Generalized Method: N/A, Tech Domain: Public Health Ethics, Strategic Method: Crisis Management Protocols, Standardized Domain Area: Public Health Ethics, Standardized Method Area: Crisis Management Protocols, Final Domain: Policy, Governance & Law, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Basel, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/935811478/101058094, Content Update Date: 2022-09-12 16:13:08, Country: CH, EC Contribution: nan, Geolocation: 47.5594078,7.58043379178956, Name: STIFTUNG GLOBALE WERTE ALLIANZ, Net EC Contribution: 0.0, Organization URL: nan, Post Code: 4056, Project ID: 101058094, Role: associatedPartner, Street: Schoenbeinstrasse 23, Total Cost of the project: 0.0, Cultural Distance: 0.3474654, Cultural Distance Std: 0.45683578, Country Name: Switzerland,EC Max Contribution: 4201758.75, EC Signature Date: 2022-05-11, End Date: 2025-08-31 00:00:00,Start Date: 2022-09-01, Status: SIGNED, Title: Pro-active Pandemic Crisis Ethics and Integrity Framework,Goal: Prepare for ethical pandemic research response, Method: International Ethics & Integrity Framework, Generalized Goal: Pandemic Preparedness & Ethics, Generalized Method: N/A, Tech Domain: Public Health Ethics, Strategic Method: Crisis Management Protocols, Standardized Domain Area: Public Health Ethics, Standardized Method Area: Crisis Management Protocols, Final Domain: Policy, Governance & Law, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Roma, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/917884520/101130898, Content Update Date: 2023-10-13 14:41:04, Country: IT, EC Contribution: 276562.5, Geolocation: 41.9270207,12.4619761, Name: CONOSCENZA E INNOVAZIONE SOCIETA ARESPONSABILITA LIMITATA SEMPLIFICATA, Net EC Contribution: 276562.5, Organization URL: nan, Post Code: 196, Project ID: 101130898, Role: participant, Street: VIA GUIDO RENI 56, Total Cost of the project: 276562.5, Cultural Distance: 0.33040646, Cultural Distance Std: -0.27066472, Country Name: Italy,EC Max Contribution: 1999250.0, EC Signature Date: 2023-09-28, End Date: 2027-02-28 00:00:00,Start Date: 2024-03-01, Status: SIGNED, Title: Advancing the zero-tolerance approach to gender-based violence in higher education and research in the European Research Area,Goal: Safe research environments for all genders, Method: Capacity building & Policy Monitoring, Generalized Goal: Safe Research Environments, Generalized Method: N/A, Tech Domain: Gender Equality Studies, Strategic Method: Societal Impact Analysis, Standardized Domain Area: Social & Political Studies, Standardized Method Area: Policy Analysis & Formulation, Final Domain: Social Sciences & Human Behavior, Final Method: Policy, Economic & Social Analysis Methods, Broad Domain: Policy/ Governance & Law, Broad Method: Qualitative, Social Inquiry & Policy Analysis', 'City: Munchen, Contact Form: https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/contact-form/project/888637759/101072224, Content Update Date: 2022-08-10 17:33:15, Country: DE, EC Contribution: 75000.0, Geolocation: 48.1343443,11.4466238, Name: KNOWING01 GMBH, Net EC Contribution: 75000.0, Organization URL: nan, Post Code: 81243, Project ID: 101072224, Role: coordinator, Street: AM STADTPARK 66, Total Cost of the project: 0.0, Cultural Distance: 0.33376053, Cultural Distance Std: -0.12619418, Country Name: Germany,EC Max Contribution: 75000.0, EC Signature Date: 2022-06-13, End Date: 2023-06-30 00:00:00,Start Date: 2022-07-01, Status: CLOSED, Title: Scale Business and Technology to Impact on Disease Research by with Lossless and Efficient Data Analysis,Goal: Streamlined Disease Research Data Analysis, Method: SaaS Data Integration & Exploitation, Generalized Goal: Accelerated Disease Research, Generalized Method: N/A, Tech Domain: Biomedical Research, Strategic Method: Data Management & Integration, Standardized Domain Area: Biomedical Research & Discovery, Standardized Method Area: Data Management & Integration, Final Domain: Biotechnology & Life Sciences, Final Method: Software Engineering & HCI Methods, Broad Domain: Health, Medicine & Biotechnology, Broad Method: Data Analysis, Modeling & Computational Approaches']\n",
            "\n",
            "Chatbot: This question seems to refer to the previous query about the highest paid project.  However, the current context does not include information about that project.  The provided project data here covers several different projects, each with its own topics.  Please specify which project you are interested in, or provide the Project ID.\n",
            "\n",
            "\n",
            "Your question: could you provide me with topics of this project: project ID 101126531\n",
            "Tool Call detected: get_project_info_by_id with args {'project_id': '101126531'}\n",
            "Tool Output: Project Details for ID: 101126531\n",
            "  Name: COALITION FOR EPIDEMIC PREPAREDNESS INNOVATIONS\n",
            "  Title: Late-stage clinical development of Chikungunya vaccines in endemic countries (CHIKV) and  Controlled Human Infection Models for SARS-CoV2 and other beta coronaviruses (CHIM).\n",
            "  Status: SIGNED\n",
            "  EC Contribution: 70000000.0\n",
            "  Net EC Contribution: 70000000.0\n",
            "  Total Cost: 100000000.0\n",
            "  Max EC Contribution: 70000000.0\n",
            "  Country: Norway\n",
            "  City: Oslo\n",
            "  Start Date: 2023-06-01 00:00:00\n",
            "  End Date: 2028-11-30 00:00:00\n",
            "  Role: coordinator\n",
            "  Goal: Advance vaccine development for epidemics\n",
            "  Method: Late-stage clinical trials & CHIM models\n",
            "  Tech Domain: Vaccine Technology\n",
            "  Organization URL: nan\n",
            "  Geolocation: 59.9221933,10.6827199\n",
            "\n",
            "\n",
            "Chatbot: Based on the provided information, the project with ID 101126531, titled \"COALITION FOR EPIDEMIC PREPAREDNESS INNOVATIONS\", deals with the following topics:\n",
            "\n",
            "* **Late-stage clinical development of Chikungunya vaccines in endemic countries (CHIKV)**\n",
            "* **Controlled Human Infection Models for SARS-CoV2 and other beta coronaviruses (CHIM)**.  \n",
            "\n",
            "More broadly, the project aims to advance vaccine development for epidemics using methods such as late-stage clinical trials and Controlled Human Infection Models (CHIM).  It appears to be focused on vaccine technology.\n",
            "\n",
            "\n",
            "Your question:  'How many projects are in London?'\n",
            "Tool Call detected: count_projects_by_city with args {'city_name': 'London'}\n",
            "Tool Output: There are 6 projects in London.\n",
            "\n",
            "Chatbot: There are 6 projects in London.\n",
            "\n",
            "\n",
            "Your question: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}